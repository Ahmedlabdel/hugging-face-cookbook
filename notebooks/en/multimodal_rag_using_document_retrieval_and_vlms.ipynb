{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgXrYJdQ5ci_"
      },
      "source": [
        "# Multimodal RAG using Document Retrieval (ColPali) and Vision Language Models (VLMs)\n",
        "\n",
        "_Authored by: [Sergio Paniego](https://github.com/sergiopaniego)_\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**üö®WARNING**: This notebooks uses a lot of computational resources. When running in Colab, it will use a A100 GPU.\n",
        "\n",
        "This notebook demonstrates how you can build a multimodal Retrieval Agumented Generation (RAG) system using a multimodal retriever model (ColPali) and how you can connect it to a Vision Language Model (Qwen2-VL) to improve your RAG system.\n",
        "\n"
      ],
      "metadata": {
        "id": "gWYSaN6CzzX8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnRb4SDvwbbs"
      },
      "source": [
        "## 1. Install dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL3-FujJ6fgW"
      },
      "source": [
        "Let‚Äôs start by installing the necessary libraries for our project!\n",
        "\n",
        "We will install transformers from source since the VLM model (Qwen2-VL) used is not yet part of the packaged version. This could be modified once the package is released.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlDOWAfa2O7m"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q byaldi pdf2image git+https://github.com/huggingface/transformers.git qwen-vl-utils flash-attn\n",
        "# Tested with byaldi==...."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also intall poppler-utils to manipulate the PDFs"
      ],
      "metadata": {
        "id": "MMExuRP6rTMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po2vHWznzhu5"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2EbYqBHc2DdS"
      },
      "outputs": [],
      "source": [
        "# Login needed because ColPali uses: https://huggingface.co/google/paligemma-3b-mix-448 // https://github.com/AnswerDotAI/byaldi?tab=readme-ov-file#colpali-access\n",
        "\n",
        "#from huggingface_hub import notebook_login\n",
        "\n",
        "#notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Dataset üìÅ\n",
        "\n",
        "For this recipe, we will use IKEA assembly instructions.\n",
        "\n",
        "To download the assembly instructions, you can follow [these steps](https://www.ikea.com/us/en/customer-service/assembly-instructions-puba2cdc880)."
      ],
      "metadata": {
        "id": "j7zxX5OB9xFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "pdfs = {\n",
        "    \"MALM\": \"https://www.ikea.com/us/en/assembly_instructions/malm-4-drawer-chest-white__AA-2398381-2-100.pdf\",\n",
        "    \"BILLY\": \"https://www.ikea.com/us/en/assembly_instructions/billy-bookcase-white__AA-1844854-6-2.pdf\",\n",
        "    \"BOAXEL\": \"https://www.ikea.com/us/en/assembly_instructions/boaxel-wall-upright-white__AA-2341341-2-100.pdf\",\n",
        "    \"ADILS\": \"https://www.ikea.com/us/en/assembly_instructions/adils-leg-white__AA-844478-6-2.pdf\",\n",
        "    \"MICKE\": \"https://www.ikea.com/us/en/assembly_instructions/micke-desk-white__AA-476626-10-100.pdf\"\n",
        "}\n",
        "\n",
        "output_dir = \"data\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for name, url in pdfs.items():\n",
        "    response = requests.get(url)\n",
        "    pdf_path = os.path.join(output_dir, f\"{name}.pdf\")\n",
        "\n",
        "    with open(pdf_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    print(f\"Downloaded {name} to {pdf_path}\")\n",
        "\n",
        "print(\"Downloaded files:\", os.listdir(output_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2XXWzzfq_VY",
        "outputId": "05d787ce-10cf-4f83-9bad-f919e674e81b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded MALM to data/MALM.pdf\n",
            "Downloaded BILLY to data/BILLY.pdf\n",
            "Downloaded BOAXEL to data/BOAXEL.pdf\n",
            "Downloaded ADILS to data/ADILS.pdf\n",
            "Downloaded MICKE to data/MICKE.pdf\n",
            "Downloaded files: ['ADILS.pdf', 'MALM.pdf', 'BILLY.pdf', 'MICKE.pdf', 'BOAXEL.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading the instructions, we will convert the PDFs to images so the document retrieval model (ColPali) can manipulate them."
      ],
      "metadata": {
        "id": "sprO33qV-MfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "\n",
        "def convert_pdfs_to_images(pdf_folder):\n",
        "    pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
        "    all_images = {}\n",
        "\n",
        "    for doc_id, pdf_file in enumerate(pdf_files):\n",
        "        pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "        images = convert_from_path(pdf_path)\n",
        "        all_images[doc_id] = images\n",
        "\n",
        "    return all_images\n",
        "\n",
        "all_images = convert_pdfs_to_images(\"/content/data/\")\n",
        "all_images[0][2]"
      ],
      "metadata": {
        "id": "Q9yHsoH59_aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Init ColPali Multimodal Document Retrieval model ü§ñ"
      ],
      "metadata": {
        "id": "FnvIrKVF_Jre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Byaldi](https://github.com/AnswerDotAI/byaldi)"
      ],
      "metadata": {
        "id": "86gbJ1nK82uU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIR4lHBaxHbH"
      },
      "outputs": [],
      "source": [
        "from byaldi import RAGMultiModalModel\n",
        "\n",
        "docs_retrieval_model = RAGMultiModalModel.from_pretrained(\"vidore/colpali-v1.2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PihMBx4s2lT4"
      },
      "source": [
        "We can directly index our documents using the documents retrieval model passing the folder where the pdfs are stored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIr_xyjxvemI"
      },
      "outputs": [],
      "source": [
        "docs_retrieval_model.index(\n",
        "    input_path=\"data/\",\n",
        "    index_name=\"image_index\",\n",
        "    store_collection_with_index=False,\n",
        "    overwrite=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaSUXku024zp"
      },
      "source": [
        "##¬†4. Let's retrieve using the Documents Retrieval Model model ü§î"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH_Px2Bx1P4l"
      },
      "outputs": [],
      "source": [
        "text_query = \"How do I assemble the Micke desk?\"\n",
        "\n",
        "results = docs_retrieval_model.search(text_query, k=3)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_images[4][0] # page_num are 1-indexed, while doc_ids are 0-indexed. Source https://github.com/AnswerDotAI/byaldi?tab=readme-ov-file#searching"
      ],
      "metadata": {
        "id": "0XvK6E7saelp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_grouped_images(results, all_images):\n",
        "    grouped_images = []\n",
        "\n",
        "    for result in results:\n",
        "        doc_id = result['doc_id']\n",
        "        page_num = result['page_num']\n",
        "        grouped_images.append(all_images[doc_id][page_num - 1])\n",
        "\n",
        "    return grouped_images\n",
        "\n",
        "grouped_images = get_grouped_images(results, all_images)"
      ],
      "metadata": {
        "id": "Fdx5IYs2b3lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_images"
      ],
      "metadata": {
        "id": "Dm4sGzbNchfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Init Visual Language Model for Question Answering üôã"
      ],
      "metadata": {
        "id": "fNgpDD6T_dCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "import torch\n",
        "\n",
        "vl_model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "    \"Qwen/Qwen2-VL-2B-Instruct\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    attn_implementation=\"flash_attention_2\", # https://huggingface.co/docs/transformers/main/en/model_doc/qwen2_vl#flash-attention-2-to-speed-up-generation\n",
        ")\n",
        "vl_model.cuda().eval()"
      ],
      "metadata": {
        "id": "wbBzZUvUwmIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lwIXDdX-6zz2"
      },
      "outputs": [],
      "source": [
        "min_pixels = 224*224\n",
        "max_pixels = 1024*1024 # https://huggingface.co/docs/transformers/main/en/model_doc/qwen2_vl#image-resolution-for-performance-boost\n",
        "vl_model_processor = Qwen2VLProcessor.from_pretrained(\n",
        "    \"Qwen/Qwen2-VL-7B-Instruct\",\n",
        "    min_pixels=min_pixels,\n",
        "    max_pixels=max_pixels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Let's assemble the vlm model and test the system üîß"
      ],
      "metadata": {
        "id": "YmtRsTU7_t5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"image\": grouped_images[0],\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"image\": grouped_images[1],\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"image\": grouped_images[2],\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": text_query\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "Rh3JUAt6w_x7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1Y36wMv09G_A"
      },
      "outputs": [],
      "source": [
        "text = vl_model_processor.apply_chat_template(\n",
        "    messages, tokenize=False, add_generation_prompt=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RVzrxpck9IlD"
      },
      "outputs": [],
      "source": [
        "image_inputs, _ = process_vision_info(messages)\n",
        "inputs = vl_model_processor(\n",
        "    text=[text],\n",
        "    images=image_inputs,\n",
        "    padding=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "inputs = inputs.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xVvsyuZb9MIh"
      },
      "outputs": [],
      "source": [
        "generated_ids = vl_model.generate(**inputs, max_new_tokens=500)\n",
        "generated_ids_trimmed = [\n",
        "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "]\n",
        "output_text = vl_model_processor.batch_decode(\n",
        "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmWNJDxQ_vS1",
        "outputId": "287596dc-f34f-4dc8-c8a5-8fcf02a38c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To assemble the Micke desk, follow these steps:\n",
            "\n",
            "1. **Prepare the Components**: Ensure all parts are clean and free of debris. Use a screwdriver to remove the protective film from the screws.\n",
            "\n",
            "2. **Position the Legs**: Place the legs of the desk on the floor, ensuring they are level and stable.\n",
            "\n",
            "3. **Install the Legs**: Insert the legs into the holes provided on the desk. Use the screws to secure the legs in place.\n",
            "\n",
            "4. **Attach the Drawers**: Place the drawers on the desk and secure them with the screws provided. Make sure the drawers are level and stable.\n",
            "\n",
            "5. **Complete Assembly**: Once all components are in place, tighten the screws to secure the desk.\n",
            "\n",
            "6. **Check for Proper Fit**: Make sure the desk is level and stable. Adjust the legs and drawers as needed.\n",
            "\n",
            "7. **Final Touches**: Clean the desk with a soft cloth and apply a protective finish if desired.\n",
            "\n",
            "By following these steps, you should be able to assemble the Micke desk successfully.\n"
          ]
        }
      ],
      "source": [
        "print(output_text[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Assembling it all! üßë‚Äçüè≠Ô∏è"
      ],
      "metadata": {
        "id": "Q_XPNoR3_zgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_with_multimodal_rag(vl_model, docs_retrieval_model, vl_model_processor, messages, grouped_images, text_query, top_k, max_new_tokens):\n",
        "    results = docs_retrieval_model.search(text_query, k=top_k)\n",
        "    grouped_images = get_grouped_images(results, all_images)\n",
        "\n",
        "    messages = [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "          {\"type\": \"image\", \"image\": image} for image in grouped_images\n",
        "            ] + [\n",
        "          {\"type\": \"text\", \"text\": text_query}\n",
        "        ],\n",
        "      }\n",
        "    ]\n",
        "\n",
        "    # Prepare the inputs\n",
        "    text = vl_model_processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, video_inputs = process_vision_info(messages)\n",
        "    inputs = vl_model_processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    inputs = inputs.to(\"cuda\")\n",
        "\n",
        "    # Generate text from the vl_model\n",
        "    generated_ids = vl_model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "    generated_ids_trimmed = [\n",
        "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "    # Decode the generated text\n",
        "    output_text = vl_model_processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "\n",
        "    return output_text\n",
        "\n",
        "output_text = answer_with_multimodal_rag(\n",
        "    vl_model=vl_model,\n",
        "    docs_retrieval_model=docs_retrieval_model,\n",
        "    vl_model_processor=vl_model_processor,\n",
        "    messages=messages,\n",
        "    grouped_images=grouped_images,\n",
        "    text_query=\"What is shown in these images?\",\n",
        "    top_k=3,\n",
        "    max_new_tokens=100\n",
        ")\n",
        "print(output_text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4qu4ZBaxC7N",
        "outputId": "28998e36-5066-42f1-f92c-a8abc3c81868"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The images in the document are part of a furniture assembly manual. Here is a detailed description of each image:\n",
            "\n",
            "1. **Image 12**: This image shows a step where the top of a cabinet is being assembled. The assembly involves inserting a screw into a hole, which is labeled with the number 8x and the part number 131372.\n",
            "\n",
            "2. **Image 13**: This image shows the bottom part of the cabinet being assembled. The assembly involves inserting a screw into a hole, which is labeled with the number 2x and the part number 109341.\n",
            "\n",
            "3. **Image 39**: This image shows a step where the top of a drawer is being assembled. The assembly involves inserting a screw into a hole, which is labeled with the number 1x and the part number 131372.\n",
            "\n",
            "4. **Image 40**: This image shows the bottom part of the drawer being assembled. The assembly involves inserting a screw into a hole, which is labeled with the number 2x and the part number 109341.\n",
            "\n",
            "5. **Image 10**: This image shows a step where the top of a cabinet is being assembled. The assembly involves inserting a screw into a hole, which is labeled with the number 2x and the part number 131372.\n",
            "\n",
            "6. **Image 11**: This image shows the bottom part of the cabinet being assembled. The assembly involves inserting a screw into a hole, which is labeled with the number 2x and the part number 109341.\n",
            "\n",
            "7. **Image 41**: This image shows the bottom part of the drawer being assembled. The assembly involves inserting a screw into a hole, which is labeled with the number 2x and the part number 109341.\n",
            "\n",
            "The images are part of a furniture assembly manual, and each step is labeled with the number of the screw and the part number, which are used to identify the screws and parts used in the assembly process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Going further üßë‚ÄçüéìÔ∏è\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "O4Oec-pZAOXu"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}